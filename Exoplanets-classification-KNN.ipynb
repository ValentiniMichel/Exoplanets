{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import stats\n",
    "\n",
    "#To get better visual of the confusion matrix:\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "             normalize=False,\n",
    "             title='Confusion matrix',\n",
    "             cmap=plt.cm.Blues):\n",
    "    #Add Normalization Option\n",
    "    '''prints pretty confusion metric with normalization option '''\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\\\\\\\\\")\n",
    "    #else:\n",
    "        #print('Confusion matrix, without normalization\\\\\\\\')\n",
    "    \n",
    "#     print(cm)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "use_pca = True\n",
    "\n",
    "#carichiamo i dati \n",
    "df = pd.read_csv(\"exoplanet.csv\")\n",
    "df.info()\n",
    "df = df.replace('CONFIRMED', 0)\n",
    "df = df.replace('CANDIDATE', 1)\n",
    "df = df.replace('FALSE POSITIVE', 2)\n",
    "df = df.fillna(0)\n",
    "\n",
    "df.to_csv(\"Exoplanet_mod.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize feature with MinMaxScaler after it we need to fit the data\n",
    "MinMaxScaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "y_data = pd.read_csv('Exoplanet_mod.csv', usecols= ['koi_disposition'])\n",
    "x_data = pd.read_csv('Exoplanet_mod.csv', usecols= ['koi_fpflag_nt','koi_fpflag_ss','koi_fpflag_co','koi_fpflag_ec','koi_period','koi_period_err1','koi_period_err2','koi_time0bk','koi_time0bk_err1','koi_time0bk_err2','koi_impact','koi_impact_err1','koi_impact_err2','koi_duration','koi_duration_err1','koi_duration_err2','koi_depth','koi_depth_err1','koi_depth_err2','koi_prad','koi_prad_err1','koi_prad_err2','koi_teq','koi_teq_err1','koi_teq_err2','koi_insol','koi_insol_err1','koi_insol_err2','koi_model_snr','koi_tce_plnt_num','koi_steff','koi_steff_err1','koi_steff_err2','koi_slogg','koi_slogg_err1','koi_slogg_err2','koi_srad','koi_srad_err1','koi_srad_err2','ra','dec','koi_kepmag'])\n",
    "\n",
    "#take the 80% of data for train and 20% for test\n",
    "x_train = x_data[:7650]\n",
    "y_train = y_data[:7650]\n",
    "\n",
    "x_test = x_data[7650:]\n",
    "y_test = y_data[7650:]\n",
    "\n",
    "x_train = x_train.values\n",
    "x_test = x_test.values\n",
    "\n",
    "print(\"Classes train : \", y_train.shape)\n",
    "print(\"Features train : \", x_train.shape)\n",
    "\n",
    "print(\"Classes test :\", y_test.shape)\n",
    "print(\"Features train : \", x_test.shape)\n",
    "\n",
    "x_train = MinMaxScaler.fit_transform(x_train)\n",
    "x_test = MinMaxScaler.fit_transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA().fit(x_train)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()\n",
    "    \n",
    "cum_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "XT = pca.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 1. Inizializzo i parametri\n",
    "\n",
    "\"\"\"\n",
    "Metrics intended for real-valued vector spaces:\n",
    "\n",
    "“euclidean” EuclideanDistance sqrt(sum((x - y)^2))\n",
    "\n",
    "“manhattan” ManhattanDistance sum(|x - y|)\n",
    "\n",
    "“chebyshev” ChebyshevDistance max(|x - y|)\n",
    "\n",
    "“minkowski” MinkowskiDistance p sum(|x - y|^p)^(1/p)\n",
    "\n",
    "“wminkowski” WMinkowskiDistance p, w sum(|w * (x - y)|^p)^(1/p)\n",
    "\n",
    "“seuclidean” SEuclideanDistance V sqrt(sum((x - y)^2 / V))\n",
    "\n",
    "“mahalanobis” MahalanobisDistance V or VI sqrt((x - y)' V^-1 (x - y))\n",
    "\"\"\"\n",
    "\n",
    " #These are the predicted output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ks = [5,7,11,13,15,17]\n",
    "funs = [\"euclidean\", \"manhattan\",\"chebyshev\",\"minkowski\"]#,\"seuclidean\",\"mahalanobis\"]\n",
    "\n",
    "V = np.cov(x_train)\n",
    "classes = ['0','1','2']\n",
    "\n",
    "def f1(x):\n",
    "    return '%1.2f' % x\n",
    "def f2(x):\n",
    "    return '%i' % x\n",
    "\n",
    "train_accuracy = np.empty(len(ks))\n",
    "test_accuracy = np.empty(len(ks))\n",
    "train_scores, test_scores = list(), list()\n",
    "\n",
    "for fun in funs:\n",
    "    i=0\n",
    "    for k in ks:\n",
    "        if fun==\"minkowski\":\n",
    "            knn_clf=KNeighborsClassifier(n_neighbors=k, weights='distance', metric=fun, p=8)\n",
    "        elif fun == \"manhattan\":\n",
    "            knn_clf=KNeighborsClassifier(n_neighbors=k, weights='distance', metric=fun, p=1)\n",
    "        else:\n",
    "            knn_clf=KNeighborsClassifier(n_neighbors=k, weights='distance', metric=fun)\n",
    "        \n",
    "        print(\"#################\", fun ,\"[K=%i]  #################\" % k)\n",
    "        knn_clf.fit(x_train,y_train)\n",
    "        predict=knn_clf.predict(x_test)\n",
    "\n",
    "        classification_metrics = metrics.classification_report(y_test, np.round(predict), target_names=classes)\n",
    "        cm_dict = metrics.classification_report(y_test, np.round(predict), target_names=classes, output_dict=True)\n",
    "        #print(\"\\nParameters (k,metric):\",k,fun)\n",
    "        print(classification_metrics)\n",
    "        print(fun[0].capitalize()+fun[1:]+\"\\\\\\\\\")\n",
    "        #print(df)\n",
    "\n",
    "        confusion_matrix= metrics.confusion_matrix(y_test, predict)\n",
    "\n",
    "        plot_confusion_matrix(confusion_matrix, classes)\n",
    "        plt.show()\n",
    "        plot_confusion_matrix(confusion_matrix, classes, normalize=True)\n",
    "        plt.show()\n",
    "\n",
    "        #test new graph to show accuracy \n",
    "        test_accuracy[i] = knn_clf.score(x_test, y_test)\n",
    "        knn_clf.fit(x_test,y_test)\n",
    "        train_accuracy[i] = knn_clf.score(x_train, y_train)\n",
    "        i = i+1\n",
    "\n",
    "    plt.plot(ks, test_accuracy, label = 'Testing dataset Accuracy')\n",
    "    plt.plot(ks, train_accuracy, label = 'Training dataset Accuracy')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.xlabel('n_neighbors')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "\n",
    "        \n",
    "        #tp, fp, tn, fn = perf_measure(y_test.values, predict)\n",
    "\n",
    "        #TSS = (tp/(tp+fn) - (fp/(fp+tn)))\n",
    "        #accuracy = (tp+tn)/(tp+fp+fn+tn)\n",
    "\n",
    "\n",
    "        #print('[tp fp tn fn] = ', tp, fp, tn, fn)\n",
    "        #print('Accuracy: ', accuracy)\n",
    "        #print('TSS: ', TSS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9dd100f9de71ce83bbfabba929d1fb833e52fa3763e9df0523c4cf0b3e4fea5d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
