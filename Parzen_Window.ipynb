{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import stats\n",
    "\n",
    "#To get better visual of the confusion matrix:\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "             normalize=False,\n",
    "             title='Confusion matrix',\n",
    "             cmap=plt.cm.Blues):\n",
    "    #Add Normalization Option\n",
    "    '''prints pretty confusion metric with normalization option '''\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\\\\\\\\\")\n",
    "    #else:\n",
    "        #print('Confusion matrix, without normalization\\\\\\\\')\n",
    "    \n",
    "#     print(cm)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "#carichiamo i dati \n",
    "df = pd.read_csv(\"exoplanet.csv\")\n",
    "#df.info()\n",
    "df = df.replace('CONFIRMED', 0)\n",
    "df = df.replace('CANDIDATE', 1)\n",
    "df = df.replace('FALSE POSITIVE', 2)\n",
    "df = df.fillna(0)\n",
    "\n",
    "df.sort_values('koi_disposition', inplace=True, ascending=False)\n",
    "df = df.iloc[2500:]\n",
    "\n",
    "shuffled = df.sample(frac=1, random_state=42)\n",
    "\n",
    "shuffled.to_csv(\"Exoplanet_mod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes for training:  (5000, 1)\n",
      "Feature for training:  (5000, 42)\n",
      "Classes for training:  (2064, 1)\n",
      "Feature for training:  (2064, 42)\n"
     ]
    }
   ],
   "source": [
    "#normalize feature with MinMaxScaler after it we need to fit the data\n",
    "MinMaxScaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "y_data = pd.read_csv('Exoplanet_mod.csv', usecols= ['koi_disposition'])#.values.transpose()[0]\n",
    "x_data = pd.read_csv('Exoplanet_mod.csv', usecols= ['koi_fpflag_nt','koi_fpflag_ss','koi_fpflag_co','koi_fpflag_ec',\n",
    "                                                    'koi_period','koi_period_err1','koi_period_err2','koi_time0bk','koi_time0bk_err1',\n",
    "                                                    'koi_time0bk_err2','koi_impact','koi_impact_err1','koi_impact_err2','koi_duration',\n",
    "                                                    'koi_duration_err1','koi_duration_err2','koi_depth','koi_depth_err1','koi_depth_err2',\n",
    "                                                    'koi_prad','koi_prad_err1','koi_prad_err2','koi_teq','koi_teq_err1','koi_teq_err2',\n",
    "                                                    'koi_insol','koi_insol_err1','koi_insol_err2','koi_model_snr','koi_tce_plnt_num',\n",
    "                                                    'koi_steff','koi_steff_err1','koi_steff_err2','koi_slogg','koi_slogg_err1',\n",
    "                                                    'koi_slogg_err2','koi_srad','koi_srad_err1','koi_srad_err2','ra','dec','koi_kepmag'])\n",
    "\n",
    "#take the 70% of data for train and 30% for test\n",
    "x_train = x_data[:5000]#5651\n",
    "y_train = y_data[:5000]\n",
    "\n",
    "x_test = x_data[5000:]\n",
    "y_test = y_data[5000:]\n",
    "\n",
    "x_train = x_train.values\n",
    "x_test = x_test.values\n",
    "\n",
    "print(\"Classes for training: \",y_train.shape)\n",
    "print(\"Feature for training: \",x_train.shape)\n",
    "\n",
    "print(\"Classes for training: \",y_test.shape)\n",
    "print(\"Feature for training: \",x_test.shape)\n",
    "\n",
    "x_train = MinMaxScaler.fit_transform(x_train)\n",
    "x_test = MinMaxScaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the mean of each feature and center the data\n",
    "m = np.mean(x_train, axis=0)\n",
    "Xc = x_train - m\n",
    "\n",
    "m1 = np.mean(x_test, axis=0)\n",
    "Xc_t = x_test - m1\n",
    "\n",
    "# Calculate the covariance matrix of the centred data\n",
    "C = np.cov(Xc, rowvar=False)\n",
    "C1 = np.cov(Xc_t, rowvar=False)\n",
    "\n",
    "# Calculate eigenvalues and eigenvectors of the covariance matrix\n",
    "lambdas, U = np.linalg.eigh(C)\n",
    "lambdas1, U1 = np.linalg.eigh(C1)\n",
    "\n",
    "# Order the eigenvalues from largest to smallest\n",
    "\n",
    "best_eig_idxs = np.argsort(lambdas)[::-1]\n",
    "best_eig = lambdas[best_eig_idxs]\n",
    "best_U = U[:, best_eig_idxs]\n",
    "\n",
    "best_eig_idxs1 = np.argsort(lambdas1)[::-1]\n",
    "best_eig1 = lambdas1[best_eig_idxs1]\n",
    "best_U1 = U1[:, best_eig_idxs1]\n",
    "\n",
    "# I construct the transformation matrix T: \n",
    "T = best_U[:, :4]\n",
    "T1 = best_U1[:, :4]\n",
    "\n",
    "# Apply the transformation to the train data, make a scatter plot of the transformed data\n",
    "# The transformation is performed via the inner product of the transformation matrix T\n",
    "# and the (centered) data matrix\n",
    "XT_train = np.dot(Xc, T)\n",
    "XT_test = np.dot(Xc_t, T1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with h=0.01 and kernel function \"rect\": 42.43002544529262%\n",
      "Accuracy with h=0.1 and kernel function \"rect\": 21.119592875318066%\n",
      "Accuracy with h=1 and kernel function \"rect\": 27.035623409669213%\n",
      "\n",
      "\n",
      "Accuracy with h=0.01 and kernel function \"gaussian\": 27.544529262086513%\n",
      "Accuracy with h=0.1 and kernel function \"gaussian\": 34.223918575063614%\n",
      "Accuracy with h=1 and kernel function \"gaussian\": 42.30279898218829%\n",
      "\n",
      "\n",
      "Accuracy with h=0.01 and kernel function \"exponential\": 32.31552162849873%\n",
      "Accuracy with h=0.1 and kernel function \"exponential\": 34.478371501272264%\n",
      "Accuracy with h=1 and kernel function \"exponential\": 32.12468193384224%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#definition of kernels\n",
    "\n",
    "def gamma(x, ktype):\n",
    "  if ktype == 'rect':\n",
    "        return 1 if abs(x[0]) <= 0.5 and abs(x[1]) <= 0.5 and abs(x[2]) <= 0.5 and abs(x[3]) <= 0.5 else 0\n",
    "  elif ktype == 'gaussian':\n",
    "        return ((2*np.pi)**(-1/2)) * np.exp(-((x[0]+x[1]+x[2]+x[3])**2/2))\n",
    "  elif ktype == 'exponential':\n",
    "        return 1/2 * np.exp(-abs(x[0]+x[1]+x[2]+x[3]))\n",
    "  else:\n",
    "        raise ValueError('Kernel type not recognized. Possible options are: \"rect\", \"gaussian\", \"exponential\".')\n",
    "\n",
    "#Set hyperparameters\n",
    "hs = [0.01,0.1,1]\n",
    "\n",
    "#from dataframe to numpy array\n",
    "temp = y_train.to_numpy()\n",
    "\n",
    "#counting number of elements of clusses for storage purpose\n",
    "bin1 = np.count_nonzero(temp == 1)\n",
    "bin0 = np.count_nonzero(temp == 0)\n",
    "bin2 = np.count_nonzero(temp == 2)\n",
    "\n",
    "#array for classes storage\n",
    "c1 = np.zeros((bin1, 4))\n",
    "c2 = np.zeros((bin2, 4))\n",
    "c0 = np.zeros((bin0, 4))\n",
    "\n",
    "f = len(temp)\n",
    "j,m,n = 0,0,0\n",
    "\n",
    "#dividing dataset with respect the 3 classes\n",
    "\n",
    "for i in range(f):\n",
    "    if temp[i]==0 and j < bin0:\n",
    "        c0[j] = XT_train[i]\n",
    "        j+=1\n",
    "    elif temp[i]==2 and m < bin2:\n",
    "        c2[m] = XT_train[i]\n",
    "        m = m+1\n",
    "    elif temp[i]==1 and n < bin1:\n",
    "        c1[n] = XT_train[i]\n",
    "        n=n+1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "kernels = [\"rect\", \"gaussian\", \"exponential\"]\n",
    "\n",
    "# Estimate the likelihood through the Parzen Windows method\n",
    "# For each test item, calculate the likelihood for each of the 3 classes. Append to predicted the class with the higher likelihood\n",
    "\n",
    "for kernel in kernels:\n",
    "    for h in hs:\n",
    "        predicted = []\n",
    "        for x_te in XT_test:\n",
    "            lik1, lik2, lik3= [], [], []\n",
    "            for x_tr in c1: \n",
    "                lik1.append(gamma((np.subtract(x_te, x_tr)/h), kernel)) # Calculate Parzen window likelihood for C1 based on the kernel\n",
    "            for x_tr in c2:\n",
    "                lik2.append(gamma((np.subtract(x_te, x_tr)/h), kernel)) # Calculate Parzen window likelihood for C2 based on the kernel\n",
    "            for x_tr in c0:\n",
    "                lik3.append(gamma((np.subtract(x_te, x_tr)/h), kernel)) # Calculate Parzen window likelihood for C0 based on the kernel\n",
    "            \n",
    "            l1, l2, l3 = 1/h * np.mean(lik1), 1/h * np.mean(lik2), 1/h * np.mean(lik3), #Â Calculate final probability of belonging to either class\n",
    "            predicted.append(np.argmax([l1,l2,l3])) # Assign the class with higher probability\n",
    "\n",
    "        y_t = y_test.values.tolist()\n",
    "\n",
    "        g = len(y_t)\n",
    "        # Calculate accuracy\n",
    "        accuracy = 0\n",
    "        for i in range(g):\n",
    "            if predicted[i] == list(y_t)[i]:\n",
    "                accuracy+=1\n",
    "        accuracy = accuracy/n\n",
    "        print(f'Accuracy with h={h} and kernel function \"{kernel}\": {accuracy*100}%')\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dd100f9de71ce83bbfabba929d1fb833e52fa3763e9df0523c4cf0b3e4fea5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
