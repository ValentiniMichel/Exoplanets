{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import csv\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "             normalize=False,\n",
    "             title='Confusion matrix',\n",
    "             cmap=plt.cm.Blues):\n",
    "    #Add Normalization Option\n",
    "    '''prints pretty confusion metric with normalization option '''\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\\\\\\\\\")\n",
    "    #else:\n",
    "        #print('Confusion matrix, without normalization\\\\\\\\')\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "#load data\n",
    "df = pd.read_csv(\"exoplanet.csv\")\n",
    "df.info()\n",
    "df = df.replace('CONFIRMED', 0)\n",
    "df = df.replace('CANDIDATE', 1)\n",
    "df = df.replace('FALSE POSITIVE', 2)\n",
    "df = df.fillna(0)\n",
    "\n",
    "df.to_csv(\"Exoplanet_mod.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize feature with MinMaxScaler after it we need to fit the data\n",
    "MinMaxScaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "y_data = pd.read_csv('Exoplanet_mod.csv', usecols= ['koi_disposition'])#.values.transpose()[0]\n",
    "x_data = pd.read_csv('Exoplanet_mod.csv', usecols= ['koi_fpflag_nt','koi_fpflag_ss','koi_fpflag_co','koi_fpflag_ec','koi_period','koi_period_err1','koi_period_err2','koi_time0bk','koi_time0bk_err1','koi_time0bk_err2','koi_impact','koi_impact_err1','koi_impact_err2','koi_duration','koi_duration_err1','koi_duration_err2','koi_depth','koi_depth_err1','koi_depth_err2','koi_prad','koi_prad_err1','koi_prad_err2','koi_teq','koi_teq_err1','koi_teq_err2','koi_insol','koi_insol_err1','koi_insol_err2','koi_model_snr','koi_tce_plnt_num','koi_steff','koi_steff_err1','koi_steff_err2','koi_slogg','koi_slogg_err1','koi_slogg_err2','koi_srad','koi_srad_err1','koi_srad_err2','ra','dec','koi_kepmag'])\n",
    "\n",
    "#take the 80% of data for train and 20% for test\n",
    "x_train = x_data[:7650]\n",
    "y_train = y_data[:7650]\n",
    "\n",
    "x_test = x_data[7650:]\n",
    "y_test = y_data[7650:]\n",
    "\n",
    "x_train = x_train.values\n",
    "x_test = x_test.values\n",
    "\n",
    "print(\"Classes train : \", y_train.shape)\n",
    "print(\"Features train : \", x_train.shape)\n",
    "\n",
    "print(\"Classes test :\", y_test.shape)\n",
    "print(\"Features train : \", x_test.shape)\n",
    "\n",
    "x_train = MinMaxScaler.fit_transform(x_train)\n",
    "x_test = MinMaxScaler.fit_transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate PCA with SKLEARN\n",
    "pca = PCA(n_components=4, svd_solver='full')\n",
    "pca_train = PCA().fit(x_train)\n",
    "pca_test = PCA().fit(x_test)\n",
    "\n",
    "cum_var = np.cumsum(pca_train.explained_variance_ratio_)\n",
    "\n",
    "plt.plot(cum_var)\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()\n",
    "\n",
    "XTrain = pca_train.transform(x_train)\n",
    "XTest = pca_train.transform(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate LDA with SKLEARN\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(x_train, y_train)\n",
    "XTrain = lda.transform(x_train)\n",
    "XTest = lda.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier without pca\n",
    "kernels = [\"rbf\",\"poly3\",\"poly5\",\"sigmoid\",\"linear\"]\n",
    "\n",
    "classes = ['0','1','2']\n",
    "\n",
    "max_iteration = -1\n",
    "for fun in kernels:\n",
    "    if fun == 'poly3':\n",
    "        model = OneVsRestClassifier(SVC(kernel='poly', degree=3, max_iter=max_iteration, probability=False, verbose=True)).fit(x_train,y_train)\n",
    "    elif fun == 'rbf':\n",
    "        model = OneVsRestClassifier(SVC(kernel='rbf', max_iter=max_iteration, probability=False, verbose=True,  C=30, gamma=1.5)).fit(x_train,y_train)\n",
    "    elif fun == 'poly5':\n",
    "        model = OneVsRestClassifier(SVC(kernel='poly', degree=5, max_iter=max_iteration, probability=False, verbose=True)).fit(x_train,y_train)\n",
    "    else:\n",
    "        model = OneVsRestClassifier(SVC(kernel=fun, max_iter=max_iteration, probability=False, verbose=True)).fit(x_train,y_train)\n",
    "    predict = model.predict(x_test)\n",
    "\n",
    "    classification_metrics = metrics.classification_report(y_test, np.round(predict), target_names=classes)\n",
    "    #cm_dict = metrics.classification_report(y_test, np.round(predict), target_names=classes, output_dict=True)\n",
    "    print(\"\\n\\n#################\", fun ,\"#################\")\n",
    "    print(\"\\n\" + classification_metrics)\n",
    "\n",
    "    confusion_matrix= metrics.confusion_matrix(y_test, predict)\n",
    "\n",
    "    plot_confusion_matrix(confusion_matrix, classes)\n",
    "    plt.show()\n",
    "    plot_confusion_matrix(confusion_matrix, classes, normalize=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier without pca\n",
    "kernels = [\"rbf\",\"poly3\",\"poly5\",\"sigmoid\",\"linear\"]\n",
    "\n",
    "classes = ['0','1','2']\n",
    "\n",
    "#clicle on different kernel, print the confiusion matrix and accuracy matrix\n",
    "max_iteration = -1\n",
    "for fun in kernels:\n",
    "    if fun == 'poly3':\n",
    "        model = OneVsRestClassifier(SVC(kernel='poly', degree=3, max_iter=max_iteration, probability=False, verbose=True)).fit(XTrain,y_train)\n",
    "    elif fun == 'rbf':\n",
    "        model = OneVsRestClassifier(SVC(kernel='rbf', max_iter=max_iteration, probability=False, verbose=True,  C=1, gamma=0.1)).fit(XTrain,y_train)\n",
    "    elif fun == 'poly5':\n",
    "        model = OneVsRestClassifier(SVC(kernel='poly', degree=5, max_iter=max_iteration, probability=False, verbose=True)).fit(XTrain,y_train)\n",
    "    else:\n",
    "        model = OneVsRestClassifier(SVC(kernel=fun, max_iter=max_iteration, probability=False, verbose=True)).fit(XTrain,y_train)\n",
    "    predict = model.predict(XTest)\n",
    "\n",
    "    classification_metrics = metrics.classification_report(y_test, np.round(predict), target_names=classes)\n",
    "    print(\"\\n\\n#################\", fun ,\"#################\")\n",
    "    print(\"\\n\" + classification_metrics)\n",
    "\n",
    "    confusion_matrix= metrics.confusion_matrix(y_test, predict)\n",
    "\n",
    "    plot_confusion_matrix(confusion_matrix, classes)\n",
    "    plt.show()\n",
    "    plot_confusion_matrix(confusion_matrix, classes, normalize=True)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9dd100f9de71ce83bbfabba929d1fb833e52fa3763e9df0523c4cf0b3e4fea5d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
